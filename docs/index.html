<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Trading Agent Documentation</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f8fafc; /* slate-50 */
        }
        .code-block {
            font-family: 'Fira Code', monospace;
            background-color: #1e293b; /* slate-800 */
            color: #e2e8f0; /* slate-200 */
            padding: 1.5rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            font-size: 0.875rem;
            line-height: 1.6;
            margin-top: 1rem;
        }
        .code-block .comment { color: #94a3b8; } /* slate-400 */
        .code-block .keyword { color: #f472b6; } /* pink-400 */
        .code-block .function { color: #60a5fa; } /* blue-400 */
        .code-block .class-name { color: #4ade80; } /* green-400 */
        .code-block .string { color: #facc15; } /* yellow-400 */
        .code-block .number { color: #f97316; } /* orange-500 */
        .code-block .parameter { color: #a78bfa; } /* violet-400 */
        h1, h2, h3 {
            color: #1e293b; /* slate-800 */
            letter-spacing: -0.025em;
        }
        h2 {
            font-size: 1.875rem;
            font-weight: 700;
            border-bottom: 2px solid #e2e8f0; /* slate-200 */
            padding-bottom: 0.5rem;
            margin-top: 2.5rem;
            margin-bottom: 1.5rem;
        }
        h3 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 2rem;
            margin-bottom: 1rem;
        }
        p, li {
            color: #475569; /* slate-600 */
            line-height: 1.7;
            margin-bottom: 1rem;
        }
        code {
            background-color: #e2e8f0; /* slate-200 */
            color: #c026d3; /* fuchsia-600 */
            padding: 0.2rem 0.4rem;
            border-radius: 0.25rem;
            font-family: 'Fira Code', monospace;
            font-size: 0.9em;
        }
        .sidebar-link {
            display: block;
            padding: 0.5rem 1rem;
            border-left: 3px solid transparent;
            color: #475569;
            transition: all 0.2s ease-in-out;
            font-size: 0.95rem;
        }
        .sidebar-link:hover {
            color: #0f172a;
            border-left-color: #cbd5e1;
        }
        .sidebar-link.active {
            color: #2563eb;
            border-left-color: #2563eb;
            font-weight: 600;
        }
        .diagram-container {
            background-color: #ffffff;
            border: 1px solid #e2e8f0;
            border-radius: 0.75rem;
            padding: 2rem;
            margin-top: 1.5rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
        }
    </style>
</head>
<body class="bg-slate-50">

    <!-- Main Container -->
    <div class="flex flex-col md:flex-row">

        <!-- Sidebar Navigation -->
        <aside class="w-full md:w-64 lg:w-72 bg-white/80 backdrop-blur-sm border-r border-slate-200 p-4 md:p-8 md:sticky top-0 h-auto md:h-screen">
            <h1 class="text-2xl font-bold text-slate-800 mb-6">Trading Agent</h1>
            <nav id="sidebar-nav">
                <a href="#overview" class="sidebar-link">Overview</a>
                <a href="#architecture" class="sidebar-link">Architecture</a>
                <a href="#rl-loop" class="sidebar-link">The RL Loop</a>
                <a href="#trading-env" class="sidebar-link">TradingEnv.py</a>
                <a href="#portfolio" class="sidebar-link">Portfolio.py</a>
                <a href="#history" class="sidebar-link">History.py</a>
                <a href="#ppo-script" class="sidebar-link">basic_ppo.py</a>
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="flex-1 p-6 md:p-10 lg:p-12">
            
            <section id="overview">
                <h2>Project Overview</h2>
                <p>
                    This project implements a financial trading agent using deep reinforcement learning. It leverages the <strong>Stable-Baselines3</strong> library for the PPO (Proximal Policy Optimization) algorithm and a custom-built <strong>Gymnasium</strong> environment to simulate trading activities.
                </p>
                <p>
                    The system is composed of several key modules: a flexible trading environment, a portfolio management system, a historical data logger, and a main script for training and evaluation. This documentation provides a detailed breakdown of each component.
                </p>
            </section>

            <section id="architecture">
                <h2>System Architecture</h2>
                <p>The entire system is designed around the interaction between the RL agent and the custom trading environment. The diagram below illustrates the relationship between the major components.</p>
                <div class="diagram-container">
                    <svg width="100%" viewBox="0 0 800 450" xmlns="http://www.w3.org/2000/svg" font-family="'Inter', sans-serif" font-size="14">
                        <!-- Main Boxes -->
                        <rect x="50" y="50" width="200" height="100" rx="10" fill="#bfdbfe" stroke="#60a5fa" stroke-width="2"/>
                        <text x="150" y="105" text-anchor="middle" font-weight="bold" fill="#1e3a8a">PPO Agent</text>
                        <text x="150" y="125" text-anchor="middle" fill="#1e40af">(Stable-Baselines3)</text>

                        <rect x="300" y="50" width="450" height="350" rx="10" fill="#dbeafe" stroke="#93c5fd" stroke-width="2"/>
                        <text x="525" y="80" text-anchor="middle" font-weight="bold" fill="#1e3a8a">TradingEnv (Gymnasium)</text>

                        <rect x="350" y="150" width="180" height="100" rx="10" fill="#ffffff" stroke="#9ca3af" stroke-width="1.5"/>
                        <text x="440" y="205" text-anchor="middle" font-weight="bold" fill="#1f2937">Portfolio.py</text>

                        <rect x="570" y="150" width="180" height="100" rx="10" fill="#ffffff" stroke="#9ca3af" stroke-width="1.5"/>
                        <text x="660" y="205" text-anchor="middle" font-weight="bold" fill="#1f2937">History.py</text>
                        
                        <rect x="350" y="280" width="400" height="100" rx="10" fill="#ffffff" stroke="#9ca3af" stroke-width="1.5"/>
                        <text x="550" y="335" text-anchor="middle" font-weight="bold" fill="#1f2937">Market Data (DataFrame)</text>

                        <!-- Arrows -->
                        <path d="M250 100 H 300" stroke="#3b82f6" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                        <text x="275" y="90" text-anchor="middle" fill="#1d4ed8">Action</text>
                        
                        <path d="M300 150 H 250" stroke="#3b82f6" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                        <text x="275" y="170" text-anchor="middle" fill="#1d4ed8">Observation, Reward</text>

                        <path d="M440 250 V 280" stroke="#4b5563" stroke-width="1.5" fill="none" marker-end="url(#arrowhead-gray)"/>
                        <text x="400" y="270" fill="#374151">Updates</text>

                        <path d="M660 250 V 280" stroke="#4b5563" stroke-width="1.5" fill="none" marker-end="url(#arrowhead-gray)"/>
                        <text x="700" y="270" fill="#374151">Logs Data</text>

                        <path d="M550 140 V 110" stroke="#4b5563" stroke-width="1.5" fill="none" marker-end="url(#arrowhead-gray)"/>
                        <text x="550" y="130" text-anchor="middle" fill="#374151">Manages</text>
                        
                        <defs>
                            <marker id="arrowhead" viewBox="0 0 10 10" refX="5" refY="5" markerWidth="6" markerHeight="6" orient="auto-start-reverse">
                                <path d="M 0 0 L 10 5 L 0 10 z" fill="#3b82f6" />
                            </marker>
                            <marker id="arrowhead-gray" viewBox="0 0 10 10" refX="5" refY="5" markerWidth="6" markerHeight="6" orient="auto-start-reverse">
                                <path d="M 0 0 L 10 5 L 0 10 z" fill="#4b5563" />
                            </marker>
                        </defs>
                    </svg>
                </div>
            </section>

            <section id="rl-loop">
                <h2>The Reinforcement Learning Loop</h2>
                <p>The core of the project is the interaction loop between the agent and the environment. This cycle repeats at every time step of the simulation:</p>
                <div class="diagram-container">
                     <svg width="100%" viewBox="0 0 800 350" xmlns="http://www.w3.org/2000/svg" font-family="'Inter', sans-serif" font-size="14">
                        <!-- Agent -->
                        <rect x="50" y="100" width="200" height="150" rx="10" fill="#fecaca" stroke="#ef4444" stroke-width="2"/>
                        <text x="150" y="140" text-anchor="middle" font-weight="bold" fill="#7f1d1d">Agent (PPO)</text>
                        <text x="150" y="180" text-anchor="middle" fill="#991b1b">1. Observes state</text>
                        <text x="150" y="200" text-anchor="middle" fill="#991b1b">2. Selects action</text>

                        <!-- Environment -->
                        <rect x="550" y="100" width="200" height="150" rx="10" fill="#dbeafe" stroke="#60a5fa" stroke-width="2"/>
                        <text x="650" y="140" text-anchor="middle" font-weight="bold" fill="#1e3a8a">Environment</text>
                        <text x="650" y="180" text-anchor="middle" fill="#1e40af">3. Executes action</text>
                        <text x="650" y="200" text-anchor="middle" fill="#1e40af">4. Computes reward</text>
                        <text x="650" y="220" text-anchor="middle" fill="#1e40af">5. Returns new state</text>

                        <!-- Arrows -->
                        <path d="M260 150 C 350 50, 450 50, 540 150" stroke="#ef4444" stroke-width="2.5" fill="none" marker-end="url(#arrowhead-red)"/>
                        <text x="400" y="90" text-anchor="middle" font-weight="bold" fill="#b91c1c">Action (e.g., Buy, Sell, Hold)</text>

                        <path d="M540 200 C 450 300, 350 300, 260 200" stroke="#3b82f6" stroke-width="2.5" fill="none" marker-end="url(#arrowhead-blue)"/>
                        <text x="400" y="280" text-anchor="middle" font-weight="bold" fill="#1d4ed8">New State (Observation) + Reward</text>
                        
                        <defs>
                            <marker id="arrowhead-red" viewBox="0 0 10 10" refX="5" refY="5" markerWidth="6" markerHeight="6" orient="auto-start-reverse">
                                <path d="M 0 0 L 10 5 L 0 10 z" fill="#ef4444" />
                            </marker>
                            <marker id="arrowhead-blue" viewBox="0 0 10 10" refX="5" refY="5" markerWidth="6" markerHeight="6" orient="auto-start-reverse">
                                <path d="M 0 0 L 10 5 L 0 10 z" fill="#3b82f6" />
                            </marker>
                        </defs>
                    </svg>
                </div>
            </section>

            <section id="trading-env">
                <h2>TradingEnv.py</h2>
                <p>This is the most critical component, defining the simulation world where the agent learns. It inherits from <code>gym.Env</code> and handles the state transitions, action execution, and reward calculation.</p>
                <h3>Key Responsibilities:</h3>
                <ul>
                    <li><strong>Data Handling:</strong> Manages the historical market data DataFrame, providing price information and features for each step.</li>
                    <li><strong>State Management:</strong> Constructs the observation for the agent at each step. This includes market features (like RSI, MACD) and dynamic features (like the agent's current position).</li>
                    <li><strong>Action Space:</strong> Defines the set of possible actions (e.g., `[-1, 0, 1]` for short, hold, long).</li>
                    <li><strong>Core Logic (`step` method):</strong> Advances the simulation by one time step, updates the portfolio based on the agent's action, calculates the reward, and checks for episode termination conditions (e.g., stop-loss, end of data).</li>
                    <li><strong>Risk Management:</strong> Implements stop-loss and take-profit mechanisms to end episodes when certain profit/loss thresholds are met.</li>
                </ul>
            </section>

            <section id="portfolio">
                <h2>Portfolio.py</h2>
                <p>This class is a stateful object that represents the agent's wallet. It abstracts away the complexities of trade execution and asset management.</p>
                <h3>Key Responsibilities:</h3>
                <ul>
                    <li><strong>Asset Tracking:</strong> Keeps track of the amount of `fiat` (e.g., USD) and `asset` (e.g., BTC) the agent holds.</li>
                    <li><strong>Valuation (`valorisation`):</strong> Calculates the total value of the portfolio at the current market price.</li>
                    <li><strong>Trade Execution (`trade_to_position`):</strong> The most complex method. It calculates the necessary buy/sell amount to reach a target position (e.g., move from 50% long to 100% long), accounting for trading fees.</li>
                    <li><strong>Interest Calculation:</strong> Manages interest payments for borrowed assets (shorting) or borrowed fiat (leverage).</li>
                </ul>
                <p>The <code>TargetPortfolio</code> is a convenience subclass that initializes a portfolio to a specific target value and position at the start of an episode.</p>
            </section>

            <section id="history">
                <h2>History.py</h2>
                <p>A simple yet powerful logger. The <code>History</code> object records all relevant information at every step of an episode, which is crucial for calculating rewards and for later analysis.</p>
                <h3>Key Responsibilities:</h3>
                <ul>
                    <li><strong>Data Storage:</strong> Uses a pre-allocated NumPy array for efficient storage of time-series data.</li>
                    <li><strong>Dynamic Schema:</strong> The columns are defined by the data passed to it on the first `set` call, making it flexible.</li>
                    <li><strong>Data Logging (`add`):</strong> Appends a new row of data for each step, including portfolio value, agent's position, reward, etc.</li>
                    <li><strong>Easy Access:</strong> Provides a dictionary-like interface (`__getitem__`) to retrieve columns or rows of historical data easily (e.g., `history['portfolio_valuation', -1]` to get the last portfolio value).</li>
                </ul>
            </section>

            <section id="ppo-script">
                <h2>basic_ppo.py</h2>
                <p>This is the main executable script that brings all the components together to train and evaluate the PPO agent.</p>
                <h3>Workflow:</h3>
                <ol class="list-decimal list-inside space-y-2">
                    <li><strong>Argument Parsing:</strong> Takes command-line arguments for the data file path, model save path, and a `--train` flag to switch between training and evaluation modes.</li>
                    <li><strong>Data Loading & Preprocessing:</strong> Loads the market data from a CSV, sets the timestamp as the index, and generates several technical features (e.g., `feature_close`, `feature_volume`).</li>
                    <li><strong>Train/Test Split:</strong> Splits the data into training and testing sets based on a hardcoded date.</li>
                    <li><strong>Environment Setup:</strong> Initializes the `TradingEnv` with the appropriate data and a set of custom parameters (positions, fees, reward function, etc.). For training, it uses `make_vec_env` from Stable-Baselines3 to create a vectorized environment, which can speed up training.</li>
                    <li><strong>Training Mode:</strong> If `--train` is specified, it initializes a PPO model with a specified neural network architecture (`MlpPolicy`) and trains it on the training data for a fixed number of timesteps. The trained model is then saved to a file.</li>
                    <li><strong>Evaluation Mode:</strong> If not in training mode, it loads the pre-trained PPO model, runs a number of evaluation episodes on the test data, and prints out performance metrics like average portfolio change and average market return.</li>
                </ol>
                <div class="code-block">
<pre><span class="comment"># Key part of the training script</span>
<span class="keyword">if</span> train_mode:
    <span class="comment"># ... environment setup ...</span>
    env = make_vec_env(<span class="string">"TradingEnv-v0"</span>,  n_envs=<span class="number">1</span>, env_kwargs=env_kwargs)
    
    policy_kwargs = dict(
        net_arch=dict(pi=[<span class="number">512</span>, <span class="number">512</span>], vf=[<span class="number">512</span>, <span class="number">512</span>]),
        activation_fn=ReLU,
    )
    model = PPO(<span class="string">"MlpPolicy"</span>, env, device=<span class="string">'cpu'</span>, verbose=<span class="number">1</span>, policy_kwargs=policy_kwargs)
    model.learn(total_timesteps=<span class="number">525960</span>*<span class="number">3</span>)
    model.save(ppo_save_file)
<span class="keyword">else</span>:
    <span class="comment"># ... evaluation loop ...</span>
    model = PPO.load(ppo_save_file, device=<span class="string">'cpu'</span>)
    <span class="keyword">while</span> not done <span class="keyword">and</span> not truncated:
        action, _states = model.predict(observation, deterministic=<span class="keyword">True</span>)
        observation, reward, done, truncated, info = env.step(action)
    <span class="comment"># ... calculate and print metrics ...</span>
</pre>
                </div>
            </section>

        </main>
    </div>

    <script>
        // Simple script for active link highlighting on scroll
        const sections = document.querySelectorAll('section');
        const navLinks = document.querySelectorAll('#sidebar-nav a');

        window.addEventListener('scroll', () => {
            let current = 'overview';
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                if (pageYOffset >= sectionTop - 60) {
                    current = section.getAttribute('id');
                }
            });

            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href').includes(current)) {
                    link.classList.add('active');
                }
            });
        });
    </script>
</body>
</html>

